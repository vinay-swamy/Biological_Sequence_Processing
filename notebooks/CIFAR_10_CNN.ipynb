{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "- I have no idea what I'm doing, but lets see how this goes\n",
    "- I'm not going to bother quite yet with too much normalization\n",
    "- Ok now gonna give on loading everything manually, just gonna use the pre loaded data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, Input, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "#one hot encode Y sets\n",
    "testYmat=to_categorical(testY)\n",
    "trainYmat=to_categorical(trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data to maximum\n",
    "trainXnorm=trainX.astype('float32') / 255.0\n",
    "testXnorm=testX.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a basic 2 layer model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  two_layer_model():\n",
    "    model = Sequential()\n",
    "    model.add(Input((32,32,3)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dense(units=10, activation='softmax')) \n",
    "    opt = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return(model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 3s 63us/sample - loss: 1.9339 - accuracy: 0.3141 - val_loss: 1.8298 - val_accuracy: 0.3589\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.7753 - accuracy: 0.3780 - val_loss: 1.7495 - val_accuracy: 0.3817\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.7063 - accuracy: 0.4051 - val_loss: 1.6814 - val_accuracy: 0.4115\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.6570 - accuracy: 0.4212 - val_loss: 1.6374 - val_accuracy: 0.4274\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.6200 - accuracy: 0.4357 - val_loss: 1.6153 - val_accuracy: 0.4302\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.5888 - accuracy: 0.4466 - val_loss: 1.5860 - val_accuracy: 0.4434\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.5608 - accuracy: 0.4561 - val_loss: 1.5832 - val_accuracy: 0.4423\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.5405 - accuracy: 0.4642 - val_loss: 1.5518 - val_accuracy: 0.4526\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.5172 - accuracy: 0.4701 - val_loss: 1.5421 - val_accuracy: 0.4518\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.4997 - accuracy: 0.4766 - val_loss: 1.5389 - val_accuracy: 0.4591\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.4841 - accuracy: 0.4832 - val_loss: 1.5133 - val_accuracy: 0.4623\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.4658 - accuracy: 0.4908 - val_loss: 1.5018 - val_accuracy: 0.4713\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.4535 - accuracy: 0.4926 - val_loss: 1.4958 - val_accuracy: 0.4733\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.4384 - accuracy: 0.4986 - val_loss: 1.4711 - val_accuracy: 0.4894\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.4229 - accuracy: 0.5006 - val_loss: 1.4715 - val_accuracy: 0.4818\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.4113 - accuracy: 0.5067 - val_loss: 1.4630 - val_accuracy: 0.4853\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.3995 - accuracy: 0.5094 - val_loss: 1.4577 - val_accuracy: 0.4864\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.3881 - accuracy: 0.5159 - val_loss: 1.4431 - val_accuracy: 0.4892\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.3761 - accuracy: 0.5182 - val_loss: 1.4645 - val_accuracy: 0.4798\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.3649 - accuracy: 0.5209 - val_loss: 1.4320 - val_accuracy: 0.4941\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.3571 - accuracy: 0.5261 - val_loss: 1.4438 - val_accuracy: 0.4912\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.3506 - accuracy: 0.5262 - val_loss: 1.4086 - val_accuracy: 0.5044\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.3391 - accuracy: 0.5307 - val_loss: 1.4247 - val_accuracy: 0.4979\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.3296 - accuracy: 0.5363 - val_loss: 1.4110 - val_accuracy: 0.5014\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.3213 - accuracy: 0.5373 - val_loss: 1.4140 - val_accuracy: 0.5002\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.3145 - accuracy: 0.5410 - val_loss: 1.3969 - val_accuracy: 0.5084\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.3056 - accuracy: 0.5441 - val_loss: 1.4202 - val_accuracy: 0.5016\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2966 - accuracy: 0.5475 - val_loss: 1.4063 - val_accuracy: 0.5078\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2917 - accuracy: 0.5477 - val_loss: 1.3985 - val_accuracy: 0.5063\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2788 - accuracy: 0.5530 - val_loss: 1.4024 - val_accuracy: 0.5037\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2779 - accuracy: 0.5510 - val_loss: 1.3912 - val_accuracy: 0.5074\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2738 - accuracy: 0.5522 - val_loss: 1.4082 - val_accuracy: 0.5027\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2626 - accuracy: 0.5583 - val_loss: 1.3837 - val_accuracy: 0.5074\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2558 - accuracy: 0.5609 - val_loss: 1.3809 - val_accuracy: 0.5133\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2465 - accuracy: 0.5651 - val_loss: 1.3734 - val_accuracy: 0.5164\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2468 - accuracy: 0.5628 - val_loss: 1.3722 - val_accuracy: 0.5128\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 2s 48us/sample - loss: 1.2380 - accuracy: 0.5670 - val_loss: 1.3846 - val_accuracy: 0.5119\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2311 - accuracy: 0.5692 - val_loss: 1.3830 - val_accuracy: 0.5158\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2254 - accuracy: 0.5720 - val_loss: 1.3782 - val_accuracy: 0.5131\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2216 - accuracy: 0.5723 - val_loss: 1.3870 - val_accuracy: 0.5107\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2123 - accuracy: 0.5763 - val_loss: 1.3908 - val_accuracy: 0.5126\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2068 - accuracy: 0.5779 - val_loss: 1.3673 - val_accuracy: 0.5188\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.2013 - accuracy: 0.5809 - val_loss: 1.3784 - val_accuracy: 0.5175\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1970 - accuracy: 0.5811 - val_loss: 1.3721 - val_accuracy: 0.5171\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1927 - accuracy: 0.5843 - val_loss: 1.3631 - val_accuracy: 0.5176\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1853 - accuracy: 0.5851 - val_loss: 1.3776 - val_accuracy: 0.5180\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1831 - accuracy: 0.5878 - val_loss: 1.3661 - val_accuracy: 0.5196\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1728 - accuracy: 0.5915 - val_loss: 1.4081 - val_accuracy: 0.5050\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1694 - accuracy: 0.5913 - val_loss: 1.3656 - val_accuracy: 0.5181\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1624 - accuracy: 0.5947 - val_loss: 1.3676 - val_accuracy: 0.5218\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1590 - accuracy: 0.5970 - val_loss: 1.3567 - val_accuracy: 0.5221\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1531 - accuracy: 0.5971 - val_loss: 1.3522 - val_accuracy: 0.5184\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1484 - accuracy: 0.5987 - val_loss: 1.3999 - val_accuracy: 0.5095\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1460 - accuracy: 0.6004 - val_loss: 1.3635 - val_accuracy: 0.5206\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1376 - accuracy: 0.6057 - val_loss: 1.4006 - val_accuracy: 0.5092\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1375 - accuracy: 0.6035 - val_loss: 1.3590 - val_accuracy: 0.5257\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1320 - accuracy: 0.6058 - val_loss: 1.3816 - val_accuracy: 0.5179\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1290 - accuracy: 0.6066 - val_loss: 1.3768 - val_accuracy: 0.5195\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1220 - accuracy: 0.6073 - val_loss: 1.3706 - val_accuracy: 0.5227\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1192 - accuracy: 0.6099 - val_loss: 1.4046 - val_accuracy: 0.5126\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1138 - accuracy: 0.6116 - val_loss: 1.3837 - val_accuracy: 0.5126\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1086 - accuracy: 0.6141 - val_loss: 1.3718 - val_accuracy: 0.5175\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1042 - accuracy: 0.6154 - val_loss: 1.3669 - val_accuracy: 0.5197\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1040 - accuracy: 0.6145 - val_loss: 1.3773 - val_accuracy: 0.5211\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.1009 - accuracy: 0.6151 - val_loss: 1.3682 - val_accuracy: 0.5224\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0915 - accuracy: 0.6190 - val_loss: 1.3584 - val_accuracy: 0.5242\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0859 - accuracy: 0.6216 - val_loss: 1.3615 - val_accuracy: 0.5261\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0869 - accuracy: 0.6210 - val_loss: 1.3796 - val_accuracy: 0.5136\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0777 - accuracy: 0.6236 - val_loss: 1.3669 - val_accuracy: 0.5219\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0759 - accuracy: 0.6233 - val_loss: 1.3664 - val_accuracy: 0.5218\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0772 - accuracy: 0.6239 - val_loss: 1.3671 - val_accuracy: 0.5215\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0700 - accuracy: 0.6258 - val_loss: 1.3990 - val_accuracy: 0.5099\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0625 - accuracy: 0.6285 - val_loss: 1.3825 - val_accuracy: 0.5190\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0637 - accuracy: 0.6279 - val_loss: 1.3550 - val_accuracy: 0.5279\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0599 - accuracy: 0.6283 - val_loss: 1.3930 - val_accuracy: 0.5166\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0543 - accuracy: 0.6319 - val_loss: 1.3561 - val_accuracy: 0.5260\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0517 - accuracy: 0.6326 - val_loss: 1.3639 - val_accuracy: 0.5214\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0455 - accuracy: 0.6339 - val_loss: 1.3833 - val_accuracy: 0.5189\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0415 - accuracy: 0.6351 - val_loss: 1.3965 - val_accuracy: 0.5223\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0384 - accuracy: 0.6366 - val_loss: 1.3722 - val_accuracy: 0.5237\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0381 - accuracy: 0.6347 - val_loss: 1.4514 - val_accuracy: 0.5025\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0313 - accuracy: 0.6398 - val_loss: 1.3854 - val_accuracy: 0.5224\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0268 - accuracy: 0.6404 - val_loss: 1.3828 - val_accuracy: 0.5224\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0274 - accuracy: 0.6399 - val_loss: 1.3987 - val_accuracy: 0.5176\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0202 - accuracy: 0.6436 - val_loss: 1.3968 - val_accuracy: 0.5200\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0192 - accuracy: 0.6424 - val_loss: 1.4206 - val_accuracy: 0.5145\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0172 - accuracy: 0.6444 - val_loss: 1.3912 - val_accuracy: 0.5130\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0104 - accuracy: 0.6473 - val_loss: 1.3885 - val_accuracy: 0.5214\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0029 - accuracy: 0.6495 - val_loss: 1.3910 - val_accuracy: 0.5134\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0029 - accuracy: 0.6483 - val_loss: 1.4029 - val_accuracy: 0.5234\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 1.0013 - accuracy: 0.6497 - val_loss: 1.4010 - val_accuracy: 0.5213\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 2s 45us/sample - loss: 0.9998 - accuracy: 0.6500 - val_loss: 1.4281 - val_accuracy: 0.5116\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 0.9934 - accuracy: 0.6522 - val_loss: 1.4526 - val_accuracy: 0.5072\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 0.9886 - accuracy: 0.6563 - val_loss: 1.3907 - val_accuracy: 0.5254\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 0.9846 - accuracy: 0.6560 - val_loss: 1.4020 - val_accuracy: 0.5204\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 0.9833 - accuracy: 0.6554 - val_loss: 1.4030 - val_accuracy: 0.5176\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 0.9844 - accuracy: 0.6560 - val_loss: 1.4105 - val_accuracy: 0.5190\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 0.9794 - accuracy: 0.6569 - val_loss: 1.4115 - val_accuracy: 0.5169\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 0.9770 - accuracy: 0.6585 - val_loss: 1.4279 - val_accuracy: 0.5124\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 2s 46us/sample - loss: 0.9713 - accuracy: 0.6591 - val_loss: 1.4149 - val_accuracy: 0.5181\n"
     ]
    }
   ],
   "source": [
    "tl_model=two_layer_model()\n",
    "tl_hist=tl_model.fit(trainXnorm, trainYmat, epochs=100, batch_size=64, validation_data=(testXnorm, testYmat), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this does not work very well, which is expected lets try something else,\n",
    "a not so basic model, including a convolution and pool layers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_CNN():\n",
    "    model = Sequential()\n",
    "    model.add(Input((32,32,3)))\n",
    "    model.add(Conv2D(filters= 32, kernel_size=(3, 3), activation='relu', padding='same',))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dense(units=10, activation='softmax')) \n",
    "    opt = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 16s 325us/sample - loss: 2.1468 - accuracy: 0.2038 - val_loss: 1.8844 - val_accuracy: 0.3289\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.7293 - accuracy: 0.3795 - val_loss: 1.5448 - val_accuracy: 0.4419\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.5088 - accuracy: 0.4613 - val_loss: 1.4078 - val_accuracy: 0.5043\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 1.3900 - accuracy: 0.5040 - val_loss: 1.3499 - val_accuracy: 0.5192\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.2995 - accuracy: 0.5367 - val_loss: 1.2730 - val_accuracy: 0.5433\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.2158 - accuracy: 0.5677 - val_loss: 1.2005 - val_accuracy: 0.5731\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.1350 - accuracy: 0.5996 - val_loss: 1.1795 - val_accuracy: 0.5796\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.0577 - accuracy: 0.6290 - val_loss: 1.0804 - val_accuracy: 0.6109\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.9892 - accuracy: 0.6519 - val_loss: 1.0599 - val_accuracy: 0.6300\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.9250 - accuracy: 0.6775 - val_loss: 0.9904 - val_accuracy: 0.6531\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.8716 - accuracy: 0.6959 - val_loss: 0.9985 - val_accuracy: 0.6512\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.8133 - accuracy: 0.7171 - val_loss: 0.9502 - val_accuracy: 0.6708\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.7620 - accuracy: 0.7366 - val_loss: 0.9325 - val_accuracy: 0.6770\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.7136 - accuracy: 0.7524 - val_loss: 0.9236 - val_accuracy: 0.6833\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.6685 - accuracy: 0.7670 - val_loss: 0.9032 - val_accuracy: 0.6898\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.6222 - accuracy: 0.7827 - val_loss: 0.9349 - val_accuracy: 0.6914\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.5674 - accuracy: 0.8050 - val_loss: 0.9259 - val_accuracy: 0.6987\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.5255 - accuracy: 0.8177 - val_loss: 0.9244 - val_accuracy: 0.7002\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.4821 - accuracy: 0.8327 - val_loss: 0.9502 - val_accuracy: 0.7010\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.4372 - accuracy: 0.8482 - val_loss: 0.9712 - val_accuracy: 0.7057\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.3937 - accuracy: 0.8626 - val_loss: 0.9952 - val_accuracy: 0.7002\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.3485 - accuracy: 0.8786 - val_loss: 1.0154 - val_accuracy: 0.7090\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.3075 - accuracy: 0.8939 - val_loss: 1.1071 - val_accuracy: 0.7000\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.2785 - accuracy: 0.9010 - val_loss: 1.0912 - val_accuracy: 0.7109\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.2395 - accuracy: 0.9173 - val_loss: 1.1867 - val_accuracy: 0.7049\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.2030 - accuracy: 0.9287 - val_loss: 1.2616 - val_accuracy: 0.6969\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.1832 - accuracy: 0.9342 - val_loss: 1.3367 - val_accuracy: 0.7042\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.1667 - accuracy: 0.9402 - val_loss: 1.3861 - val_accuracy: 0.6954\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.1374 - accuracy: 0.9515 - val_loss: 1.5401 - val_accuracy: 0.7006\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.1224 - accuracy: 0.9567 - val_loss: 1.5351 - val_accuracy: 0.7035\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.1147 - accuracy: 0.9591 - val_loss: 1.6571 - val_accuracy: 0.6935\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.0882 - accuracy: 0.9696 - val_loss: 1.6970 - val_accuracy: 0.7052\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0837 - accuracy: 0.9706 - val_loss: 1.8793 - val_accuracy: 0.6817\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.0913 - accuracy: 0.9668 - val_loss: 1.7647 - val_accuracy: 0.7014\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.0699 - accuracy: 0.9757 - val_loss: 1.7785 - val_accuracy: 0.7073\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.0592 - accuracy: 0.9798 - val_loss: 1.8388 - val_accuracy: 0.7027\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.0566 - accuracy: 0.9805 - val_loss: 1.9038 - val_accuracy: 0.7116\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0515 - accuracy: 0.9824 - val_loss: 2.0577 - val_accuracy: 0.7058\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.0559 - accuracy: 0.9807 - val_loss: 1.9879 - val_accuracy: 0.7083\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.0564 - accuracy: 0.9801 - val_loss: 2.0550 - val_accuracy: 0.7025\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0515 - accuracy: 0.9818 - val_loss: 2.1651 - val_accuracy: 0.7065\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0471 - accuracy: 0.9837 - val_loss: 2.0971 - val_accuracy: 0.7106\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0487 - accuracy: 0.9826 - val_loss: 2.0355 - val_accuracy: 0.7098\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 13s 268us/sample - loss: 0.0332 - accuracy: 0.9891 - val_loss: 2.3412 - val_accuracy: 0.7022\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.0369 - accuracy: 0.9874 - val_loss: 2.1487 - val_accuracy: 0.7048\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.0327 - accuracy: 0.9886 - val_loss: 2.2233 - val_accuracy: 0.7066\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0221 - accuracy: 0.9932 - val_loss: 2.3495 - val_accuracy: 0.7007\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0304 - accuracy: 0.9896 - val_loss: 2.2695 - val_accuracy: 0.7118\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0276 - accuracy: 0.9909 - val_loss: 2.2836 - val_accuracy: 0.7140\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0079 - accuracy: 0.9978 - val_loss: 2.5448 - val_accuracy: 0.7119\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0147 - accuracy: 0.9951 - val_loss: 2.4621 - val_accuracy: 0.7104\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0307 - accuracy: 0.9897 - val_loss: 2.4272 - val_accuracy: 0.7146\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0393 - accuracy: 0.9865 - val_loss: 2.3476 - val_accuracy: 0.7123\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 0.0243 - accuracy: 0.9917 - val_loss: 2.4716 - val_accuracy: 0.7101\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.0046 - accuracy: 0.9990 - val_loss: 2.5176 - val_accuracy: 0.7229\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 5.6413e-04 - accuracy: 1.0000 - val_loss: 2.5638 - val_accuracy: 0.7239\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 2.5177e-04 - accuracy: 1.0000 - val_loss: 2.6189 - val_accuracy: 0.7258\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 1.8382e-04 - accuracy: 1.0000 - val_loss: 2.6547 - val_accuracy: 0.7255\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 1.5328e-04 - accuracy: 1.0000 - val_loss: 2.6858 - val_accuracy: 0.7264\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 1.3365e-04 - accuracy: 1.0000 - val_loss: 2.7154 - val_accuracy: 0.7267\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 1.1885e-04 - accuracy: 1.0000 - val_loss: 2.7391 - val_accuracy: 0.7268\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 1.0749e-04 - accuracy: 1.0000 - val_loss: 2.7602 - val_accuracy: 0.7275\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 9.8593e-05 - accuracy: 1.0000 - val_loss: 2.7777 - val_accuracy: 0.7265\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 9.0950e-05 - accuracy: 1.0000 - val_loss: 2.7967 - val_accuracy: 0.7278\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 8.4613e-05 - accuracy: 1.0000 - val_loss: 2.8135 - val_accuracy: 0.7272\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 7.9130e-05 - accuracy: 1.0000 - val_loss: 2.8290 - val_accuracy: 0.7275\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 7.4453e-05 - accuracy: 1.0000 - val_loss: 2.8433 - val_accuracy: 0.7271\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 7.0149e-05 - accuracy: 1.0000 - val_loss: 2.8576 - val_accuracy: 0.7274\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 6.6579e-05 - accuracy: 1.0000 - val_loss: 2.8690 - val_accuracy: 0.7275\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 6.3157e-05 - accuracy: 1.0000 - val_loss: 2.8837 - val_accuracy: 0.7277\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 6.0274e-05 - accuracy: 1.0000 - val_loss: 2.8937 - val_accuracy: 0.7276\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 5.7625e-05 - accuracy: 1.0000 - val_loss: 2.9052 - val_accuracy: 0.7285\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 5.5117e-05 - accuracy: 1.0000 - val_loss: 2.9168 - val_accuracy: 0.7283\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 5.3002e-05 - accuracy: 1.0000 - val_loss: 2.9261 - val_accuracy: 0.7284\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 5.0932e-05 - accuracy: 1.0000 - val_loss: 2.9363 - val_accuracy: 0.7281\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 4.9013e-05 - accuracy: 1.0000 - val_loss: 2.9466 - val_accuracy: 0.7284\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 4.7241e-05 - accuracy: 1.0000 - val_loss: 2.9554 - val_accuracy: 0.7280\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 4.5675e-05 - accuracy: 1.0000 - val_loss: 2.9642 - val_accuracy: 0.7277\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 4.4124e-05 - accuracy: 1.0000 - val_loss: 2.9724 - val_accuracy: 0.7278\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 13s 268us/sample - loss: 4.2758e-05 - accuracy: 1.0000 - val_loss: 2.9808 - val_accuracy: 0.7279\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 13s 268us/sample - loss: 4.1422e-05 - accuracy: 1.0000 - val_loss: 2.9888 - val_accuracy: 0.7280\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 4.0166e-05 - accuracy: 1.0000 - val_loss: 2.9971 - val_accuracy: 0.7280\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 3.9038e-05 - accuracy: 1.0000 - val_loss: 3.0039 - val_accuracy: 0.7283\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 3.7942e-05 - accuracy: 1.0000 - val_loss: 3.0113 - val_accuracy: 0.7285\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 3.6873e-05 - accuracy: 1.0000 - val_loss: 3.0190 - val_accuracy: 0.7280\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 13s 268us/sample - loss: 3.5942e-05 - accuracy: 1.0000 - val_loss: 3.0258 - val_accuracy: 0.7283\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 3.5022e-05 - accuracy: 1.0000 - val_loss: 3.0323 - val_accuracy: 0.7279\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 3.4140e-05 - accuracy: 1.0000 - val_loss: 3.0392 - val_accuracy: 0.7282\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 3.3290e-05 - accuracy: 1.0000 - val_loss: 3.0462 - val_accuracy: 0.7284\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 3.2540e-05 - accuracy: 1.0000 - val_loss: 3.0522 - val_accuracy: 0.7283\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 13s 268us/sample - loss: 3.1784e-05 - accuracy: 1.0000 - val_loss: 3.0578 - val_accuracy: 0.7285\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 13s 268us/sample - loss: 3.1079e-05 - accuracy: 1.0000 - val_loss: 3.0634 - val_accuracy: 0.7286\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 13s 268us/sample - loss: 3.0378e-05 - accuracy: 1.0000 - val_loss: 3.0693 - val_accuracy: 0.7289\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 2.9732e-05 - accuracy: 1.0000 - val_loss: 3.0755 - val_accuracy: 0.7293\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 13s 268us/sample - loss: 2.9118e-05 - accuracy: 1.0000 - val_loss: 3.0810 - val_accuracy: 0.7291\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 2.8494e-05 - accuracy: 1.0000 - val_loss: 3.0868 - val_accuracy: 0.7290\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 2.7961e-05 - accuracy: 1.0000 - val_loss: 3.0921 - val_accuracy: 0.7294\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 2.7391e-05 - accuracy: 1.0000 - val_loss: 3.0976 - val_accuracy: 0.7289\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 13s 267us/sample - loss: 2.6875e-05 - accuracy: 1.0000 - val_loss: 3.1025 - val_accuracy: 0.7288\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 13s 268us/sample - loss: 2.6365e-05 - accuracy: 1.0000 - val_loss: 3.1073 - val_accuracy: 0.7288\n"
     ]
    }
   ],
   "source": [
    "history = basic_CNN().fit(trainXnorm, trainYmat, epochs=100, batch_size=64, validation_data=(testXnorm, testYmat), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the basic CNN has converged to 1m but the validation accuracy is still pretty low, so the model is overfitting \n",
    "lets try adding a dropout regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_with_dropout():\n",
    "    model = Sequential()\n",
    "    model.add(Input((32,32,3)))\n",
    "    model.add(Conv2D(filters= 32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',  padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dense(units=10, activation='softmax')) \n",
    "    opt = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 18s 363us/sample - loss: 2.2067 - accuracy: 0.1692 - val_loss: 2.0488 - val_accuracy: 0.2426\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 14s 273us/sample - loss: 1.9332 - accuracy: 0.2988 - val_loss: 1.8186 - val_accuracy: 0.3539\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 1.7560 - accuracy: 0.3660 - val_loss: 1.6143 - val_accuracy: 0.4194\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 1.6202 - accuracy: 0.4135 - val_loss: 1.4888 - val_accuracy: 0.4617\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 1.5157 - accuracy: 0.4506 - val_loss: 1.3966 - val_accuracy: 0.4890\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 1.4280 - accuracy: 0.4832 - val_loss: 1.3169 - val_accuracy: 0.5220\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 1.3538 - accuracy: 0.5120 - val_loss: 1.2520 - val_accuracy: 0.5516\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 1.2903 - accuracy: 0.5361 - val_loss: 1.1917 - val_accuracy: 0.5727\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 1.2224 - accuracy: 0.5645 - val_loss: 1.1304 - val_accuracy: 0.5975\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 1.1704 - accuracy: 0.5836 - val_loss: 1.0864 - val_accuracy: 0.6125\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 1.1195 - accuracy: 0.6049 - val_loss: 1.0319 - val_accuracy: 0.6333\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 1.0681 - accuracy: 0.6219 - val_loss: 1.0432 - val_accuracy: 0.6303\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 1.0288 - accuracy: 0.6368 - val_loss: 0.9726 - val_accuracy: 0.6578\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.9886 - accuracy: 0.6503 - val_loss: 0.9388 - val_accuracy: 0.6696\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.9536 - accuracy: 0.6661 - val_loss: 0.9701 - val_accuracy: 0.6611\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 14s 275us/sample - loss: 0.9196 - accuracy: 0.6777 - val_loss: 0.9072 - val_accuracy: 0.6798\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.8910 - accuracy: 0.6881 - val_loss: 0.8516 - val_accuracy: 0.6998\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 14s 275us/sample - loss: 0.8566 - accuracy: 0.7002 - val_loss: 0.8494 - val_accuracy: 0.7046\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.8313 - accuracy: 0.7096 - val_loss: 0.8846 - val_accuracy: 0.6890\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.8115 - accuracy: 0.7156 - val_loss: 0.8187 - val_accuracy: 0.7145\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.7776 - accuracy: 0.7271 - val_loss: 0.7926 - val_accuracy: 0.7214\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.7640 - accuracy: 0.7324 - val_loss: 0.7884 - val_accuracy: 0.7232\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.7398 - accuracy: 0.7428 - val_loss: 0.7701 - val_accuracy: 0.7342\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.7183 - accuracy: 0.7481 - val_loss: 0.7617 - val_accuracy: 0.7355\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.6977 - accuracy: 0.7550 - val_loss: 0.7302 - val_accuracy: 0.7492\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.6784 - accuracy: 0.7627 - val_loss: 0.7289 - val_accuracy: 0.7519\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.6583 - accuracy: 0.7720 - val_loss: 0.7155 - val_accuracy: 0.7527\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.6435 - accuracy: 0.7760 - val_loss: 0.7139 - val_accuracy: 0.7559\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.6294 - accuracy: 0.7802 - val_loss: 0.6904 - val_accuracy: 0.7631\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.6083 - accuracy: 0.7882 - val_loss: 0.6803 - val_accuracy: 0.7663\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.5916 - accuracy: 0.7920 - val_loss: 0.7196 - val_accuracy: 0.7578\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.5742 - accuracy: 0.7976 - val_loss: 0.7004 - val_accuracy: 0.7663\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.5623 - accuracy: 0.8027 - val_loss: 0.6685 - val_accuracy: 0.7730\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.5470 - accuracy: 0.8067 - val_loss: 0.6749 - val_accuracy: 0.7741\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.5346 - accuracy: 0.8124 - val_loss: 0.6610 - val_accuracy: 0.7730\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.5200 - accuracy: 0.8179 - val_loss: 0.6558 - val_accuracy: 0.7806\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.5104 - accuracy: 0.8207 - val_loss: 0.6578 - val_accuracy: 0.7777\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.4921 - accuracy: 0.8281 - val_loss: 0.6486 - val_accuracy: 0.7795\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.4816 - accuracy: 0.8291 - val_loss: 0.6557 - val_accuracy: 0.7789\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.4705 - accuracy: 0.8341 - val_loss: 0.6379 - val_accuracy: 0.7864\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.4584 - accuracy: 0.8376 - val_loss: 0.6597 - val_accuracy: 0.7828\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.4479 - accuracy: 0.8417 - val_loss: 0.6439 - val_accuracy: 0.7864\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.4349 - accuracy: 0.8464 - val_loss: 0.6442 - val_accuracy: 0.7861\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 14s 275us/sample - loss: 0.4303 - accuracy: 0.8483 - val_loss: 0.6472 - val_accuracy: 0.7893\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 14s 275us/sample - loss: 0.4163 - accuracy: 0.8511 - val_loss: 0.6457 - val_accuracy: 0.7885\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 14s 275us/sample - loss: 0.4052 - accuracy: 0.8559 - val_loss: 0.6485 - val_accuracy: 0.7902\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.3957 - accuracy: 0.8599 - val_loss: 0.6193 - val_accuracy: 0.7942\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.3877 - accuracy: 0.8613 - val_loss: 0.6420 - val_accuracy: 0.7880\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.3767 - accuracy: 0.8661 - val_loss: 0.6511 - val_accuracy: 0.7875\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.3667 - accuracy: 0.8695 - val_loss: 0.6581 - val_accuracy: 0.7895\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.3565 - accuracy: 0.8734 - val_loss: 0.6678 - val_accuracy: 0.7920\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.3443 - accuracy: 0.8763 - val_loss: 0.6529 - val_accuracy: 0.7934\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.3401 - accuracy: 0.8789 - val_loss: 0.6549 - val_accuracy: 0.7971\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.3306 - accuracy: 0.8833 - val_loss: 0.6660 - val_accuracy: 0.7884\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.3227 - accuracy: 0.8853 - val_loss: 0.6464 - val_accuracy: 0.7966\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.3173 - accuracy: 0.8844 - val_loss: 0.6443 - val_accuracy: 0.7981\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.3023 - accuracy: 0.8927 - val_loss: 0.6501 - val_accuracy: 0.8007\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2959 - accuracy: 0.8941 - val_loss: 0.6648 - val_accuracy: 0.7981\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2888 - accuracy: 0.8965 - val_loss: 0.7050 - val_accuracy: 0.7908\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2788 - accuracy: 0.8997 - val_loss: 0.6904 - val_accuracy: 0.7947\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2769 - accuracy: 0.9006 - val_loss: 0.6801 - val_accuracy: 0.7981\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2703 - accuracy: 0.9042 - val_loss: 0.7084 - val_accuracy: 0.7956\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2610 - accuracy: 0.9059 - val_loss: 0.6815 - val_accuracy: 0.7952\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 14s 275us/sample - loss: 0.2535 - accuracy: 0.9084 - val_loss: 0.6918 - val_accuracy: 0.8010\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2490 - accuracy: 0.9087 - val_loss: 0.6899 - val_accuracy: 0.8013\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 14s 275us/sample - loss: 0.2458 - accuracy: 0.9110 - val_loss: 0.6971 - val_accuracy: 0.7990\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2331 - accuracy: 0.9148 - val_loss: 0.7074 - val_accuracy: 0.8012\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2298 - accuracy: 0.9170 - val_loss: 0.7090 - val_accuracy: 0.8021\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2240 - accuracy: 0.9205 - val_loss: 0.7066 - val_accuracy: 0.8002\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2180 - accuracy: 0.9213 - val_loss: 0.7249 - val_accuracy: 0.8010\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2181 - accuracy: 0.9218 - val_loss: 0.7201 - val_accuracy: 0.8001\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2097 - accuracy: 0.9250 - val_loss: 0.7345 - val_accuracy: 0.8021\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.2040 - accuracy: 0.9270 - val_loss: 0.7520 - val_accuracy: 0.7965\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 14s 275us/sample - loss: 0.1997 - accuracy: 0.9282 - val_loss: 0.7379 - val_accuracy: 0.7977\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1941 - accuracy: 0.9299 - val_loss: 0.7330 - val_accuracy: 0.7984\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1891 - accuracy: 0.9312 - val_loss: 0.7546 - val_accuracy: 0.8011\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1830 - accuracy: 0.9330 - val_loss: 0.7563 - val_accuracy: 0.8003\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1808 - accuracy: 0.9349 - val_loss: 0.7540 - val_accuracy: 0.8035\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1823 - accuracy: 0.9351 - val_loss: 0.7481 - val_accuracy: 0.7999\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1708 - accuracy: 0.9392 - val_loss: 0.7746 - val_accuracy: 0.8015\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1713 - accuracy: 0.9384 - val_loss: 0.7846 - val_accuracy: 0.8038\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1717 - accuracy: 0.9378 - val_loss: 0.7745 - val_accuracy: 0.7979\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1615 - accuracy: 0.9426 - val_loss: 0.7508 - val_accuracy: 0.8043\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1619 - accuracy: 0.9413 - val_loss: 0.7926 - val_accuracy: 0.8025\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1615 - accuracy: 0.9423 - val_loss: 0.7784 - val_accuracy: 0.8020\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1522 - accuracy: 0.9455 - val_loss: 0.8027 - val_accuracy: 0.8016\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1474 - accuracy: 0.9469 - val_loss: 0.7952 - val_accuracy: 0.8016\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1444 - accuracy: 0.9473 - val_loss: 0.8261 - val_accuracy: 0.8006\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1436 - accuracy: 0.9490 - val_loss: 0.8146 - val_accuracy: 0.8029\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1418 - accuracy: 0.9498 - val_loss: 0.8051 - val_accuracy: 0.8079\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1443 - accuracy: 0.9476 - val_loss: 0.7880 - val_accuracy: 0.8053\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1363 - accuracy: 0.9517 - val_loss: 0.7980 - val_accuracy: 0.8073\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1365 - accuracy: 0.9516 - val_loss: 0.8166 - val_accuracy: 0.8049\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1298 - accuracy: 0.9535 - val_loss: 0.8307 - val_accuracy: 0.8054\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1272 - accuracy: 0.9539 - val_loss: 0.8513 - val_accuracy: 0.8053\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1258 - accuracy: 0.9544 - val_loss: 0.8254 - val_accuracy: 0.8049\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1252 - accuracy: 0.9544 - val_loss: 0.8233 - val_accuracy: 0.8068\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1234 - accuracy: 0.9554 - val_loss: 0.8422 - val_accuracy: 0.8065\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1197 - accuracy: 0.9577 - val_loss: 0.8708 - val_accuracy: 0.8036\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 14s 274us/sample - loss: 0.1188 - accuracy: 0.9580 - val_loss: 0.8379 - val_accuracy: 0.8033\n"
     ]
    }
   ],
   "source": [
    "hist_dp=CNN_with_dropout().fit(trainXnorm, trainYmat, epochs=100, batch_size=64, validation_data=(testXnorm, testYmat), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this helped a little with the validation los, but it still looks like the model is over fitting. Lets try changing the weight initialization. `he_normal` is supposed to to be good for relu activation functions, and change the optimizer to `adam` with defgault settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_dropout_he_initialization():\n",
    "    model = Sequential()\n",
    "    model.add(Input((32,32,3)))\n",
    "    model.add(Conv2D(filters= 32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform',padding='same'))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform' , padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(units=10, activation='softmax')) \n",
    "    opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 15s 307us/sample - loss: 1.5680 - accuracy: 0.4299 - val_loss: 1.1899 - val_accuracy: 0.5650\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 1.0692 - accuracy: 0.6179 - val_loss: 0.9131 - val_accuracy: 0.6757\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.8878 - accuracy: 0.6854 - val_loss: 0.8787 - val_accuracy: 0.6941\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.7706 - accuracy: 0.7281 - val_loss: 0.7579 - val_accuracy: 0.7398\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.6882 - accuracy: 0.7570 - val_loss: 0.6645 - val_accuracy: 0.7690\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.6198 - accuracy: 0.7805 - val_loss: 0.6630 - val_accuracy: 0.7709\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.5691 - accuracy: 0.7998 - val_loss: 0.6564 - val_accuracy: 0.7813\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.5339 - accuracy: 0.8123 - val_loss: 0.6373 - val_accuracy: 0.7835\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.4951 - accuracy: 0.8262 - val_loss: 0.6324 - val_accuracy: 0.7946\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.4614 - accuracy: 0.8373 - val_loss: 0.6340 - val_accuracy: 0.7943\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.4349 - accuracy: 0.8445 - val_loss: 0.6106 - val_accuracy: 0.8005\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.4152 - accuracy: 0.8521 - val_loss: 0.6204 - val_accuracy: 0.7968\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.3945 - accuracy: 0.8611 - val_loss: 0.6324 - val_accuracy: 0.8057\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.3735 - accuracy: 0.8658 - val_loss: 0.6046 - val_accuracy: 0.8142\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.3537 - accuracy: 0.8743 - val_loss: 0.6285 - val_accuracy: 0.8080\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.3342 - accuracy: 0.8819 - val_loss: 0.6229 - val_accuracy: 0.8079\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.3298 - accuracy: 0.8833 - val_loss: 0.6541 - val_accuracy: 0.8055\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.3141 - accuracy: 0.8883 - val_loss: 0.6729 - val_accuracy: 0.8023\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.3091 - accuracy: 0.8897 - val_loss: 0.6495 - val_accuracy: 0.8078\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.2927 - accuracy: 0.8957 - val_loss: 0.6657 - val_accuracy: 0.8085\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.2835 - accuracy: 0.8992 - val_loss: 0.6816 - val_accuracy: 0.8059\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.2813 - accuracy: 0.9013 - val_loss: 0.6867 - val_accuracy: 0.8089\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.2679 - accuracy: 0.9061 - val_loss: 0.6520 - val_accuracy: 0.8121\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.2701 - accuracy: 0.9038 - val_loss: 0.6991 - val_accuracy: 0.8125\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.2552 - accuracy: 0.9102 - val_loss: 0.6844 - val_accuracy: 0.8084\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.2579 - accuracy: 0.9080 - val_loss: 0.6981 - val_accuracy: 0.8067\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.2495 - accuracy: 0.9126 - val_loss: 0.6987 - val_accuracy: 0.8133\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.2410 - accuracy: 0.9148 - val_loss: 0.7201 - val_accuracy: 0.8111\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.2330 - accuracy: 0.9184 - val_loss: 0.7050 - val_accuracy: 0.8162\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.2373 - accuracy: 0.9164 - val_loss: 0.7189 - val_accuracy: 0.8130\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.2281 - accuracy: 0.9183 - val_loss: 0.7144 - val_accuracy: 0.8099\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.2237 - accuracy: 0.9228 - val_loss: 0.7282 - val_accuracy: 0.8159\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.2217 - accuracy: 0.9223 - val_loss: 0.7449 - val_accuracy: 0.8086\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.2138 - accuracy: 0.9257 - val_loss: 0.7493 - val_accuracy: 0.8123\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.2125 - accuracy: 0.9266 - val_loss: 0.7181 - val_accuracy: 0.8145\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.2074 - accuracy: 0.9284 - val_loss: 0.7327 - val_accuracy: 0.8118\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.2063 - accuracy: 0.9271 - val_loss: 0.7786 - val_accuracy: 0.8046\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.2108 - accuracy: 0.9270 - val_loss: 0.7778 - val_accuracy: 0.8173\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.2064 - accuracy: 0.9295 - val_loss: 0.7899 - val_accuracy: 0.8154\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1959 - accuracy: 0.9320 - val_loss: 0.7771 - val_accuracy: 0.8090\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.2050 - accuracy: 0.9283 - val_loss: 0.7685 - val_accuracy: 0.8123\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1973 - accuracy: 0.9331 - val_loss: 0.7871 - val_accuracy: 0.8134\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1873 - accuracy: 0.9359 - val_loss: 0.8232 - val_accuracy: 0.8086\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1930 - accuracy: 0.9342 - val_loss: 0.7819 - val_accuracy: 0.8133\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1879 - accuracy: 0.9347 - val_loss: 0.7694 - val_accuracy: 0.8143\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1882 - accuracy: 0.9347 - val_loss: 0.7820 - val_accuracy: 0.8155\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1843 - accuracy: 0.9364 - val_loss: 0.7721 - val_accuracy: 0.8122\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1866 - accuracy: 0.9365 - val_loss: 0.7632 - val_accuracy: 0.8113\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1882 - accuracy: 0.9358 - val_loss: 0.8022 - val_accuracy: 0.8174\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1801 - accuracy: 0.9386 - val_loss: 0.8075 - val_accuracy: 0.8109\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1870 - accuracy: 0.9371 - val_loss: 0.8293 - val_accuracy: 0.8120\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1743 - accuracy: 0.9401 - val_loss: 0.8382 - val_accuracy: 0.8126\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1784 - accuracy: 0.9397 - val_loss: 0.7889 - val_accuracy: 0.8144\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1773 - accuracy: 0.9396 - val_loss: 0.8040 - val_accuracy: 0.8179\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1797 - accuracy: 0.9388 - val_loss: 0.8300 - val_accuracy: 0.8006\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1772 - accuracy: 0.9400 - val_loss: 0.8577 - val_accuracy: 0.8110\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1765 - accuracy: 0.9397 - val_loss: 0.8401 - val_accuracy: 0.8085\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1711 - accuracy: 0.9420 - val_loss: 0.8159 - val_accuracy: 0.8209\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1743 - accuracy: 0.9398 - val_loss: 0.8443 - val_accuracy: 0.8092\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1726 - accuracy: 0.9416 - val_loss: 0.8890 - val_accuracy: 0.7992\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1715 - accuracy: 0.9423 - val_loss: 0.8269 - val_accuracy: 0.8174\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1693 - accuracy: 0.9437 - val_loss: 0.8409 - val_accuracy: 0.8091\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1679 - accuracy: 0.9439 - val_loss: 0.8293 - val_accuracy: 0.8172\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1650 - accuracy: 0.9444 - val_loss: 0.8368 - val_accuracy: 0.8127\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1641 - accuracy: 0.9447 - val_loss: 0.8239 - val_accuracy: 0.8177\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1668 - accuracy: 0.9443 - val_loss: 0.8253 - val_accuracy: 0.8177\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1778 - accuracy: 0.9400 - val_loss: 0.8238 - val_accuracy: 0.8195\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1589 - accuracy: 0.9477 - val_loss: 0.8527 - val_accuracy: 0.8103\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1662 - accuracy: 0.9444 - val_loss: 0.8383 - val_accuracy: 0.8161\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1646 - accuracy: 0.9448 - val_loss: 0.8469 - val_accuracy: 0.8135\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1627 - accuracy: 0.9452 - val_loss: 0.8679 - val_accuracy: 0.8179\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1600 - accuracy: 0.9472 - val_loss: 0.8583 - val_accuracy: 0.8116\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1663 - accuracy: 0.9459 - val_loss: 0.8397 - val_accuracy: 0.8131\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1587 - accuracy: 0.9476 - val_loss: 0.8339 - val_accuracy: 0.8181\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1582 - accuracy: 0.9471 - val_loss: 0.8960 - val_accuracy: 0.8145\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1662 - accuracy: 0.9450 - val_loss: 0.8496 - val_accuracy: 0.8137\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1546 - accuracy: 0.9495 - val_loss: 0.9044 - val_accuracy: 0.8081\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1603 - accuracy: 0.9467 - val_loss: 0.8269 - val_accuracy: 0.8167\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1549 - accuracy: 0.9487 - val_loss: 0.8752 - val_accuracy: 0.8137\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1657 - accuracy: 0.9457 - val_loss: 0.8708 - val_accuracy: 0.8158\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1580 - accuracy: 0.9480 - val_loss: 0.8690 - val_accuracy: 0.8149\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1588 - accuracy: 0.9476 - val_loss: 0.8585 - val_accuracy: 0.8159\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1608 - accuracy: 0.9466 - val_loss: 0.8837 - val_accuracy: 0.8171\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1598 - accuracy: 0.9482 - val_loss: 0.8715 - val_accuracy: 0.8156\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1529 - accuracy: 0.9500 - val_loss: 0.8847 - val_accuracy: 0.8191\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1495 - accuracy: 0.9502 - val_loss: 0.9114 - val_accuracy: 0.8182\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1532 - accuracy: 0.9495 - val_loss: 0.9100 - val_accuracy: 0.8118\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 15s 299us/sample - loss: 0.1562 - accuracy: 0.9492 - val_loss: 0.9223 - val_accuracy: 0.8104\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1569 - accuracy: 0.9480 - val_loss: 0.8957 - val_accuracy: 0.8147\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1642 - accuracy: 0.9469 - val_loss: 0.8313 - val_accuracy: 0.8155\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1588 - accuracy: 0.9482 - val_loss: 0.9129 - val_accuracy: 0.8106\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1523 - accuracy: 0.9514 - val_loss: 0.9707 - val_accuracy: 0.8091\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1545 - accuracy: 0.9504 - val_loss: 0.9090 - val_accuracy: 0.8115\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1503 - accuracy: 0.9508 - val_loss: 0.9112 - val_accuracy: 0.8155\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1513 - accuracy: 0.9503 - val_loss: 0.8965 - val_accuracy: 0.8135\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1572 - accuracy: 0.9492 - val_loss: 0.9057 - val_accuracy: 0.8110\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1583 - accuracy: 0.9486 - val_loss: 0.9467 - val_accuracy: 0.8079\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1548 - accuracy: 0.9497 - val_loss: 0.9154 - val_accuracy: 0.8154\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 14s 282us/sample - loss: 0.1524 - accuracy: 0.9513 - val_loss: 0.9292 - val_accuracy: 0.8147\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 14s 283us/sample - loss: 0.1502 - accuracy: 0.9512 - val_loss: 0.9466 - val_accuracy: 0.8063\n"
     ]
    }
   ],
   "source": [
    "hist3=CNN_dropout_he_initialization().fit(trainXnorm, trainYmat, epochs=100, batch_size=64, validation_data=(testXnorm, testYmat), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like it got a littl stuck towards the end, gonna try and reduce number of epochs to 65, and add batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_dropout_he_initialization_batchnorm():\n",
    "    model = Sequential()\n",
    "    model.add(Input((32,32,3)))\n",
    "    #conv block 1\n",
    "    model.add(Conv2D(filters= 32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform' , padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    #conv block 2\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    #conv block 3\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    model.add(Flatten())\n",
    "    #dense layers \n",
    "    model.add(Dense(units=128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(units=10, activation='softmax')) \n",
    "    opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/65\n",
      "50000/50000 [==============================] - 20s 394us/sample - loss: 1.3628 - accuracy: 0.5139 - val_loss: 1.0060 - val_accuracy: 0.6526\n",
      "Epoch 2/65\n",
      "50000/50000 [==============================] - 18s 353us/sample - loss: 0.8991 - accuracy: 0.6821 - val_loss: 0.8160 - val_accuracy: 0.7160\n",
      "Epoch 3/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.7313 - accuracy: 0.7444 - val_loss: 0.7417 - val_accuracy: 0.7465\n",
      "Epoch 4/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.6315 - accuracy: 0.7774 - val_loss: 0.6498 - val_accuracy: 0.7784\n",
      "Epoch 5/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.5554 - accuracy: 0.8059 - val_loss: 0.6419 - val_accuracy: 0.7850\n",
      "Epoch 6/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.5005 - accuracy: 0.8234 - val_loss: 0.5798 - val_accuracy: 0.8043\n",
      "Epoch 7/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.4444 - accuracy: 0.8426 - val_loss: 0.5724 - val_accuracy: 0.8065\n",
      "Epoch 8/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.3942 - accuracy: 0.8602 - val_loss: 0.5930 - val_accuracy: 0.8041\n",
      "Epoch 9/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.3612 - accuracy: 0.8722 - val_loss: 0.5797 - val_accuracy: 0.8108\n",
      "Epoch 10/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.3281 - accuracy: 0.8845 - val_loss: 0.6062 - val_accuracy: 0.8095\n",
      "Epoch 11/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.2953 - accuracy: 0.8954 - val_loss: 0.5787 - val_accuracy: 0.8261\n",
      "Epoch 12/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.2701 - accuracy: 0.9039 - val_loss: 0.6036 - val_accuracy: 0.8193\n",
      "Epoch 13/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.2499 - accuracy: 0.9109 - val_loss: 0.6505 - val_accuracy: 0.8175\n",
      "Epoch 14/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.2343 - accuracy: 0.9169 - val_loss: 0.6362 - val_accuracy: 0.8193\n",
      "Epoch 15/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.2157 - accuracy: 0.9230 - val_loss: 0.6746 - val_accuracy: 0.8173\n",
      "Epoch 16/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.2033 - accuracy: 0.9276 - val_loss: 0.6200 - val_accuracy: 0.8227\n",
      "Epoch 17/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1825 - accuracy: 0.9334 - val_loss: 0.6573 - val_accuracy: 0.8273\n",
      "Epoch 18/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1740 - accuracy: 0.9384 - val_loss: 0.6497 - val_accuracy: 0.8327\n",
      "Epoch 19/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1650 - accuracy: 0.9404 - val_loss: 0.7154 - val_accuracy: 0.8235\n",
      "Epoch 20/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1642 - accuracy: 0.9423 - val_loss: 0.6746 - val_accuracy: 0.8312\n",
      "Epoch 21/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1470 - accuracy: 0.9480 - val_loss: 0.7329 - val_accuracy: 0.8197\n",
      "Epoch 22/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1443 - accuracy: 0.9491 - val_loss: 0.7073 - val_accuracy: 0.8293\n",
      "Epoch 23/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1414 - accuracy: 0.9498 - val_loss: 0.7674 - val_accuracy: 0.8207\n",
      "Epoch 24/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1313 - accuracy: 0.9536 - val_loss: 0.6970 - val_accuracy: 0.8353\n",
      "Epoch 25/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1291 - accuracy: 0.9546 - val_loss: 0.7457 - val_accuracy: 0.8260\n",
      "Epoch 26/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1239 - accuracy: 0.9569 - val_loss: 0.7323 - val_accuracy: 0.8294\n",
      "Epoch 27/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1176 - accuracy: 0.9589 - val_loss: 0.7149 - val_accuracy: 0.8326\n",
      "Epoch 28/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1152 - accuracy: 0.9595 - val_loss: 0.7410 - val_accuracy: 0.8300\n",
      "Epoch 29/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1135 - accuracy: 0.9602 - val_loss: 0.7869 - val_accuracy: 0.8231\n",
      "Epoch 30/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1077 - accuracy: 0.9617 - val_loss: 0.7608 - val_accuracy: 0.8323\n",
      "Epoch 31/65\n",
      "50000/50000 [==============================] - 18s 353us/sample - loss: 0.1058 - accuracy: 0.9641 - val_loss: 0.7558 - val_accuracy: 0.8318\n",
      "Epoch 32/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.1039 - accuracy: 0.9632 - val_loss: 0.7318 - val_accuracy: 0.8377\n",
      "Epoch 33/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0970 - accuracy: 0.9666 - val_loss: 0.7734 - val_accuracy: 0.8345\n",
      "Epoch 34/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0997 - accuracy: 0.9659 - val_loss: 0.8714 - val_accuracy: 0.8213\n",
      "Epoch 35/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0957 - accuracy: 0.9675 - val_loss: 0.8140 - val_accuracy: 0.8275\n",
      "Epoch 36/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0906 - accuracy: 0.9686 - val_loss: 0.7926 - val_accuracy: 0.8316\n",
      "Epoch 37/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0927 - accuracy: 0.9684 - val_loss: 0.7766 - val_accuracy: 0.8325\n",
      "Epoch 38/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0852 - accuracy: 0.9699 - val_loss: 0.7923 - val_accuracy: 0.8377\n",
      "Epoch 39/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0808 - accuracy: 0.9722 - val_loss: 0.8134 - val_accuracy: 0.8297\n",
      "Epoch 40/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0829 - accuracy: 0.9710 - val_loss: 0.7839 - val_accuracy: 0.8361\n",
      "Epoch 41/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0827 - accuracy: 0.9721 - val_loss: 0.7951 - val_accuracy: 0.8316\n",
      "Epoch 42/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0830 - accuracy: 0.9706 - val_loss: 0.7842 - val_accuracy: 0.8389\n",
      "Epoch 43/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0798 - accuracy: 0.9730 - val_loss: 0.7641 - val_accuracy: 0.8386\n",
      "Epoch 44/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0766 - accuracy: 0.9738 - val_loss: 0.7964 - val_accuracy: 0.8300\n",
      "Epoch 45/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0752 - accuracy: 0.9744 - val_loss: 0.7971 - val_accuracy: 0.8371\n",
      "Epoch 46/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0707 - accuracy: 0.9751 - val_loss: 0.8190 - val_accuracy: 0.8345\n",
      "Epoch 47/65\n",
      "50000/50000 [==============================] - 18s 353us/sample - loss: 0.0733 - accuracy: 0.9751 - val_loss: 0.8316 - val_accuracy: 0.8282\n",
      "Epoch 48/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0697 - accuracy: 0.9762 - val_loss: 0.8725 - val_accuracy: 0.8295\n",
      "Epoch 49/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0706 - accuracy: 0.9761 - val_loss: 0.8742 - val_accuracy: 0.8307\n",
      "Epoch 50/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0683 - accuracy: 0.9770 - val_loss: 0.8103 - val_accuracy: 0.8317\n",
      "Epoch 51/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0686 - accuracy: 0.9765 - val_loss: 0.7940 - val_accuracy: 0.8365\n",
      "Epoch 52/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0698 - accuracy: 0.9764 - val_loss: 0.7980 - val_accuracy: 0.8374\n",
      "Epoch 53/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0640 - accuracy: 0.9781 - val_loss: 0.8816 - val_accuracy: 0.8369\n",
      "Epoch 54/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0606 - accuracy: 0.9791 - val_loss: 0.8831 - val_accuracy: 0.8256\n",
      "Epoch 55/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0659 - accuracy: 0.9774 - val_loss: 0.8348 - val_accuracy: 0.8413\n",
      "Epoch 56/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0595 - accuracy: 0.9794 - val_loss: 0.8175 - val_accuracy: 0.8404\n",
      "Epoch 57/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0639 - accuracy: 0.9788 - val_loss: 0.8345 - val_accuracy: 0.8346\n",
      "Epoch 58/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0592 - accuracy: 0.9795 - val_loss: 0.8846 - val_accuracy: 0.8361\n",
      "Epoch 59/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0570 - accuracy: 0.9804 - val_loss: 0.8101 - val_accuracy: 0.8406\n",
      "Epoch 60/65\n",
      "50000/50000 [==============================] - 18s 351us/sample - loss: 0.0615 - accuracy: 0.9798 - val_loss: 0.8699 - val_accuracy: 0.8345\n",
      "Epoch 61/65\n",
      "50000/50000 [==============================] - 18s 351us/sample - loss: 0.0583 - accuracy: 0.9800 - val_loss: 0.8045 - val_accuracy: 0.8468\n",
      "Epoch 62/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0564 - accuracy: 0.9809 - val_loss: 0.8828 - val_accuracy: 0.8324\n",
      "Epoch 63/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0587 - accuracy: 0.9796 - val_loss: 0.8703 - val_accuracy: 0.8350\n",
      "Epoch 64/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0543 - accuracy: 0.9811 - val_loss: 0.8872 - val_accuracy: 0.8364\n",
      "Epoch 65/65\n",
      "50000/50000 [==============================] - 18s 352us/sample - loss: 0.0585 - accuracy: 0.9804 - val_loss: 0.8828 - val_accuracy: 0.8373\n"
     ]
    }
   ],
   "source": [
    "hist4=CNN_dropout_he_initialization_batchnorm().fit(trainXnorm, trainYmat, epochs=65, batch_size=64, validation_data=(testXnorm, testYmat), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like this helped a fair amount; lets see if adding an extra dense layer helps, and adding dropout and batch norm for the dense layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_extra_dense():\n",
    "    model = Sequential()\n",
    "    model.add(Input((32,32,3)))\n",
    "    #conv block 1\n",
    "    model.add(Conv2D(filters= 32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform' , padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    #conv block 2\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    #conv block 3\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    model.add(Flatten())\n",
    "    #dense layers \n",
    "    model.add(Dense(units=256, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(Dense(units=128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(Dense(units=10, activation='softmax')) \n",
    "    opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/65\n",
      "50000/50000 [==============================] - 21s 428us/sample - loss: 1.7720 - accuracy: 0.3969 - val_loss: 1.4734 - val_accuracy: 0.4875\n",
      "Epoch 2/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 1.1689 - accuracy: 0.5846 - val_loss: 1.0227 - val_accuracy: 0.6415\n",
      "Epoch 3/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.9598 - accuracy: 0.6682 - val_loss: 0.8498 - val_accuracy: 0.7033\n",
      "Epoch 4/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.8376 - accuracy: 0.7115 - val_loss: 0.7050 - val_accuracy: 0.7577\n",
      "Epoch 5/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.7495 - accuracy: 0.7413 - val_loss: 0.7610 - val_accuracy: 0.7381\n",
      "Epoch 6/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.6794 - accuracy: 0.7702 - val_loss: 0.6623 - val_accuracy: 0.7725\n",
      "Epoch 7/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.6201 - accuracy: 0.7881 - val_loss: 0.5968 - val_accuracy: 0.7931\n",
      "Epoch 8/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.5776 - accuracy: 0.8056 - val_loss: 0.5873 - val_accuracy: 0.8015\n",
      "Epoch 9/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.5369 - accuracy: 0.8199 - val_loss: 0.5535 - val_accuracy: 0.8135\n",
      "Epoch 10/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.4949 - accuracy: 0.8338 - val_loss: 0.5343 - val_accuracy: 0.8214\n",
      "Epoch 11/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.4660 - accuracy: 0.8437 - val_loss: 0.5387 - val_accuracy: 0.8243\n",
      "Epoch 12/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.4367 - accuracy: 0.8544 - val_loss: 0.5495 - val_accuracy: 0.8238\n",
      "Epoch 13/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.4085 - accuracy: 0.8647 - val_loss: 0.4996 - val_accuracy: 0.8366\n",
      "Epoch 14/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.3820 - accuracy: 0.8719 - val_loss: 0.5771 - val_accuracy: 0.8182\n",
      "Epoch 15/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.3677 - accuracy: 0.8763 - val_loss: 0.4886 - val_accuracy: 0.8434\n",
      "Epoch 16/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.3455 - accuracy: 0.8837 - val_loss: 0.5078 - val_accuracy: 0.8352\n",
      "Epoch 17/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.3331 - accuracy: 0.8866 - val_loss: 0.5098 - val_accuracy: 0.8351\n",
      "Epoch 18/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.3166 - accuracy: 0.8936 - val_loss: 0.4893 - val_accuracy: 0.8484\n",
      "Epoch 19/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.3034 - accuracy: 0.8974 - val_loss: 0.5060 - val_accuracy: 0.8431\n",
      "Epoch 20/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.2817 - accuracy: 0.9044 - val_loss: 0.5159 - val_accuracy: 0.8407\n",
      "Epoch 21/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.2782 - accuracy: 0.9060 - val_loss: 0.4840 - val_accuracy: 0.8528\n",
      "Epoch 22/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.2615 - accuracy: 0.9106 - val_loss: 0.5101 - val_accuracy: 0.8471\n",
      "Epoch 23/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.2512 - accuracy: 0.9159 - val_loss: 0.5285 - val_accuracy: 0.8477\n",
      "Epoch 24/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.2411 - accuracy: 0.9179 - val_loss: 0.5099 - val_accuracy: 0.8508\n",
      "Epoch 25/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.2369 - accuracy: 0.9198 - val_loss: 0.5162 - val_accuracy: 0.8487\n",
      "Epoch 26/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.2251 - accuracy: 0.9235 - val_loss: 0.5097 - val_accuracy: 0.8536\n",
      "Epoch 27/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.2204 - accuracy: 0.9253 - val_loss: 0.5023 - val_accuracy: 0.8578\n",
      "Epoch 28/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.2177 - accuracy: 0.9271 - val_loss: 0.5065 - val_accuracy: 0.8492\n",
      "Epoch 29/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.2084 - accuracy: 0.9296 - val_loss: 0.5821 - val_accuracy: 0.8381\n",
      "Epoch 30/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.2036 - accuracy: 0.9310 - val_loss: 0.4875 - val_accuracy: 0.8601\n",
      "Epoch 31/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1931 - accuracy: 0.9339 - val_loss: 0.5530 - val_accuracy: 0.8452\n",
      "Epoch 32/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1902 - accuracy: 0.9351 - val_loss: 0.5186 - val_accuracy: 0.8528\n",
      "Epoch 33/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1855 - accuracy: 0.9380 - val_loss: 0.5303 - val_accuracy: 0.8565\n",
      "Epoch 34/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1819 - accuracy: 0.9395 - val_loss: 0.5355 - val_accuracy: 0.8525\n",
      "Epoch 35/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.1741 - accuracy: 0.9407 - val_loss: 0.5400 - val_accuracy: 0.8528\n",
      "Epoch 36/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.1737 - accuracy: 0.9411 - val_loss: 0.5272 - val_accuracy: 0.8557\n",
      "Epoch 37/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.1678 - accuracy: 0.9427 - val_loss: 0.5353 - val_accuracy: 0.8564\n",
      "Epoch 38/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1630 - accuracy: 0.9436 - val_loss: 0.5470 - val_accuracy: 0.8540\n",
      "Epoch 39/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1573 - accuracy: 0.9459 - val_loss: 0.5305 - val_accuracy: 0.8571\n",
      "Epoch 40/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1592 - accuracy: 0.9454 - val_loss: 0.5694 - val_accuracy: 0.8490\n",
      "Epoch 41/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1552 - accuracy: 0.9469 - val_loss: 0.5477 - val_accuracy: 0.8575\n",
      "Epoch 42/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.1537 - accuracy: 0.9479 - val_loss: 0.5431 - val_accuracy: 0.8576\n",
      "Epoch 43/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1447 - accuracy: 0.9507 - val_loss: 0.5697 - val_accuracy: 0.8527\n",
      "Epoch 44/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1416 - accuracy: 0.9520 - val_loss: 0.5611 - val_accuracy: 0.8542\n",
      "Epoch 45/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.1393 - accuracy: 0.9528 - val_loss: 0.5594 - val_accuracy: 0.8593\n",
      "Epoch 46/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1359 - accuracy: 0.9534 - val_loss: 0.6075 - val_accuracy: 0.8428\n",
      "Epoch 47/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1336 - accuracy: 0.9549 - val_loss: 0.5535 - val_accuracy: 0.8543\n",
      "Epoch 48/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1386 - accuracy: 0.9549 - val_loss: 0.5656 - val_accuracy: 0.8544\n",
      "Epoch 49/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1345 - accuracy: 0.9547 - val_loss: 0.5536 - val_accuracy: 0.8560\n",
      "Epoch 50/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1268 - accuracy: 0.9561 - val_loss: 0.5666 - val_accuracy: 0.8545\n",
      "Epoch 51/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1308 - accuracy: 0.9561 - val_loss: 0.5505 - val_accuracy: 0.8611\n",
      "Epoch 52/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1280 - accuracy: 0.9570 - val_loss: 0.5747 - val_accuracy: 0.8557\n",
      "Epoch 53/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1258 - accuracy: 0.9580 - val_loss: 0.5398 - val_accuracy: 0.8608\n",
      "Epoch 54/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1200 - accuracy: 0.9596 - val_loss: 0.5447 - val_accuracy: 0.8598\n",
      "Epoch 55/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1209 - accuracy: 0.9592 - val_loss: 0.5322 - val_accuracy: 0.8607\n",
      "Epoch 56/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.1220 - accuracy: 0.9583 - val_loss: 0.5790 - val_accuracy: 0.8542\n",
      "Epoch 57/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1207 - accuracy: 0.9600 - val_loss: 0.5709 - val_accuracy: 0.8574\n",
      "Epoch 58/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1150 - accuracy: 0.9613 - val_loss: 0.5608 - val_accuracy: 0.8605\n",
      "Epoch 59/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1140 - accuracy: 0.9615 - val_loss: 0.6166 - val_accuracy: 0.8485\n",
      "Epoch 60/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1136 - accuracy: 0.9627 - val_loss: 0.5642 - val_accuracy: 0.8578\n",
      "Epoch 61/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1129 - accuracy: 0.9616 - val_loss: 0.5602 - val_accuracy: 0.8599\n",
      "Epoch 62/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1128 - accuracy: 0.9618 - val_loss: 0.5567 - val_accuracy: 0.8630\n",
      "Epoch 63/65\n",
      "50000/50000 [==============================] - 19s 372us/sample - loss: 0.1126 - accuracy: 0.9627 - val_loss: 0.5441 - val_accuracy: 0.8643\n",
      "Epoch 64/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1055 - accuracy: 0.9642 - val_loss: 0.5677 - val_accuracy: 0.8607\n",
      "Epoch 65/65\n",
      "50000/50000 [==============================] - 19s 373us/sample - loss: 0.1110 - accuracy: 0.9630 - val_loss: 0.5672 - val_accuracy: 0.8583\n"
     ]
    }
   ],
   "source": [
    "hist5=CNN_extra_dense().fit(trainXnorm, trainYmat, epochs=65, batch_size=64, validation_data=(testXnorm, testYmat), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay, so this tooks a little longer, but we got the best results so far. Now im gonna add a 4 convolutional block and see what happens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_4_convs():\n",
    "    model = Sequential()\n",
    "    model.add(Input((32,32,3)))\n",
    "    #conv block 1\n",
    "    model.add(Conv2D(filters= 32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform' , padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    #conv block 2\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    #conv block 3\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    #conv block 4\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    model.add(Flatten())\n",
    "    #dense layers \n",
    "    model.add(Dense(units=256, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(Dense(units=128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(Dense(units=10, activation='softmax')) \n",
    "    opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/65\n",
      "50000/50000 [==============================] - 28s 553us/sample - loss: 1.8477 - accuracy: 0.3659 - val_loss: 1.3917 - val_accuracy: 0.5049\n",
      "Epoch 2/65\n",
      "50000/50000 [==============================] - 24s 489us/sample - loss: 1.2173 - accuracy: 0.5671 - val_loss: 1.0281 - val_accuracy: 0.6312\n",
      "Epoch 3/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.9729 - accuracy: 0.6631 - val_loss: 0.8518 - val_accuracy: 0.7035\n",
      "Epoch 4/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.8290 - accuracy: 0.7197 - val_loss: 0.8041 - val_accuracy: 0.7317\n",
      "Epoch 5/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.7243 - accuracy: 0.7555 - val_loss: 0.6741 - val_accuracy: 0.7694\n",
      "Epoch 6/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.6489 - accuracy: 0.7823 - val_loss: 0.6751 - val_accuracy: 0.7734\n",
      "Epoch 7/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.5827 - accuracy: 0.8058 - val_loss: 0.5748 - val_accuracy: 0.8081\n",
      "Epoch 8/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.5288 - accuracy: 0.8236 - val_loss: 0.5796 - val_accuracy: 0.8091\n",
      "Epoch 9/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.4826 - accuracy: 0.8394 - val_loss: 0.5382 - val_accuracy: 0.8235\n",
      "Epoch 10/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.4332 - accuracy: 0.8557 - val_loss: 0.5658 - val_accuracy: 0.8183\n",
      "Epoch 11/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.3987 - accuracy: 0.8679 - val_loss: 0.6050 - val_accuracy: 0.8054\n",
      "Epoch 12/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.3690 - accuracy: 0.8779 - val_loss: 0.5157 - val_accuracy: 0.8328\n",
      "Epoch 13/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.3351 - accuracy: 0.8899 - val_loss: 0.5487 - val_accuracy: 0.8287\n",
      "Epoch 14/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.3089 - accuracy: 0.8976 - val_loss: 0.5545 - val_accuracy: 0.8302\n",
      "Epoch 15/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.2841 - accuracy: 0.9063 - val_loss: 0.5634 - val_accuracy: 0.8280\n",
      "Epoch 16/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.2692 - accuracy: 0.9120 - val_loss: 0.5111 - val_accuracy: 0.8462\n",
      "Epoch 17/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.2477 - accuracy: 0.9176 - val_loss: 0.4905 - val_accuracy: 0.8543\n",
      "Epoch 18/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.2221 - accuracy: 0.9258 - val_loss: 0.5256 - val_accuracy: 0.8438\n",
      "Epoch 19/65\n",
      "50000/50000 [==============================] - 24s 487us/sample - loss: 0.2101 - accuracy: 0.9308 - val_loss: 0.5428 - val_accuracy: 0.8465\n",
      "Epoch 20/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.2045 - accuracy: 0.9329 - val_loss: 0.5286 - val_accuracy: 0.8526\n",
      "Epoch 21/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1912 - accuracy: 0.9370 - val_loss: 0.5490 - val_accuracy: 0.8481\n",
      "Epoch 22/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1784 - accuracy: 0.9415 - val_loss: 0.5764 - val_accuracy: 0.8438\n",
      "Epoch 23/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1661 - accuracy: 0.9452 - val_loss: 0.5901 - val_accuracy: 0.8375\n",
      "Epoch 24/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1610 - accuracy: 0.9475 - val_loss: 0.5712 - val_accuracy: 0.8497\n",
      "Epoch 25/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1497 - accuracy: 0.9513 - val_loss: 0.5701 - val_accuracy: 0.8456\n",
      "Epoch 26/65\n",
      "50000/50000 [==============================] - 24s 487us/sample - loss: 0.1470 - accuracy: 0.9522 - val_loss: 0.5690 - val_accuracy: 0.8520\n",
      "Epoch 27/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1451 - accuracy: 0.9519 - val_loss: 0.5704 - val_accuracy: 0.8527\n",
      "Epoch 28/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1388 - accuracy: 0.9553 - val_loss: 0.5861 - val_accuracy: 0.8502\n",
      "Epoch 29/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1318 - accuracy: 0.9561 - val_loss: 0.5575 - val_accuracy: 0.8581\n",
      "Epoch 30/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1251 - accuracy: 0.9585 - val_loss: 0.5734 - val_accuracy: 0.8552\n",
      "Epoch 31/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1190 - accuracy: 0.9608 - val_loss: 0.6009 - val_accuracy: 0.8518\n",
      "Epoch 32/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1156 - accuracy: 0.9622 - val_loss: 0.6213 - val_accuracy: 0.8437\n",
      "Epoch 33/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1142 - accuracy: 0.9620 - val_loss: 0.6069 - val_accuracy: 0.8543\n",
      "Epoch 34/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1073 - accuracy: 0.9650 - val_loss: 0.6257 - val_accuracy: 0.8457\n",
      "Epoch 35/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1037 - accuracy: 0.9667 - val_loss: 0.5963 - val_accuracy: 0.8518\n",
      "Epoch 36/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.1018 - accuracy: 0.9662 - val_loss: 0.6369 - val_accuracy: 0.8515\n",
      "Epoch 37/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0992 - accuracy: 0.9673 - val_loss: 0.6265 - val_accuracy: 0.8493\n",
      "Epoch 38/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0982 - accuracy: 0.9677 - val_loss: 0.6114 - val_accuracy: 0.8573\n",
      "Epoch 39/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0981 - accuracy: 0.9684 - val_loss: 0.6121 - val_accuracy: 0.8561\n",
      "Epoch 40/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0899 - accuracy: 0.9711 - val_loss: 0.5846 - val_accuracy: 0.8589\n",
      "Epoch 41/65\n",
      "50000/50000 [==============================] - 24s 487us/sample - loss: 0.0953 - accuracy: 0.9684 - val_loss: 0.5833 - val_accuracy: 0.8580\n",
      "Epoch 42/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0903 - accuracy: 0.9701 - val_loss: 0.5932 - val_accuracy: 0.8590\n",
      "Epoch 43/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0864 - accuracy: 0.9720 - val_loss: 0.6074 - val_accuracy: 0.8560\n",
      "Epoch 44/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0847 - accuracy: 0.9723 - val_loss: 0.6156 - val_accuracy: 0.8550\n",
      "Epoch 45/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0872 - accuracy: 0.9725 - val_loss: 0.6191 - val_accuracy: 0.8555\n",
      "Epoch 46/65\n",
      "50000/50000 [==============================] - 24s 487us/sample - loss: 0.0812 - accuracy: 0.9731 - val_loss: 0.6416 - val_accuracy: 0.8530\n",
      "Epoch 47/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0762 - accuracy: 0.9746 - val_loss: 0.6215 - val_accuracy: 0.8630\n",
      "Epoch 48/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0761 - accuracy: 0.9759 - val_loss: 0.6443 - val_accuracy: 0.8527\n",
      "Epoch 49/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0731 - accuracy: 0.9768 - val_loss: 0.6226 - val_accuracy: 0.8565\n",
      "Epoch 50/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0756 - accuracy: 0.9759 - val_loss: 0.5976 - val_accuracy: 0.8627\n",
      "Epoch 51/65\n",
      "50000/50000 [==============================] - 24s 487us/sample - loss: 0.0729 - accuracy: 0.9761 - val_loss: 0.6526 - val_accuracy: 0.8512\n",
      "Epoch 52/65\n",
      "50000/50000 [==============================] - 24s 487us/sample - loss: 0.0732 - accuracy: 0.9762 - val_loss: 0.7038 - val_accuracy: 0.8394\n",
      "Epoch 53/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0732 - accuracy: 0.9766 - val_loss: 0.6040 - val_accuracy: 0.8597\n",
      "Epoch 54/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0702 - accuracy: 0.9768 - val_loss: 0.6541 - val_accuracy: 0.8578\n",
      "Epoch 55/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0697 - accuracy: 0.9774 - val_loss: 0.6474 - val_accuracy: 0.8586\n",
      "Epoch 56/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0635 - accuracy: 0.9788 - val_loss: 0.6328 - val_accuracy: 0.8613\n",
      "Epoch 57/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0652 - accuracy: 0.9790 - val_loss: 0.6348 - val_accuracy: 0.8606\n",
      "Epoch 58/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0657 - accuracy: 0.9784 - val_loss: 0.6365 - val_accuracy: 0.8621\n",
      "Epoch 59/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0637 - accuracy: 0.9799 - val_loss: 0.6739 - val_accuracy: 0.8565\n",
      "Epoch 60/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0638 - accuracy: 0.9789 - val_loss: 0.6742 - val_accuracy: 0.8567\n",
      "Epoch 61/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0587 - accuracy: 0.9807 - val_loss: 0.6563 - val_accuracy: 0.8603\n",
      "Epoch 62/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0638 - accuracy: 0.9795 - val_loss: 0.6260 - val_accuracy: 0.8626\n",
      "Epoch 63/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0593 - accuracy: 0.9815 - val_loss: 0.6688 - val_accuracy: 0.8559\n",
      "Epoch 64/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0603 - accuracy: 0.9802 - val_loss: 0.6377 - val_accuracy: 0.8597\n",
      "Epoch 65/65\n",
      "50000/50000 [==============================] - 24s 488us/sample - loss: 0.0571 - accuracy: 0.9814 - val_loss: 0.6671 - val_accuracy: 0.8566\n"
     ]
    }
   ],
   "source": [
    "hist7=CNN_4_convs().fit(trainXnorm, trainYmat, epochs=65, batch_size=64, validation_data=(testXnorm, testYmat), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mariginally worse - lets try the previous version with an extra dense layer before softmaxing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_more_dense():\n",
    "    model = Sequential()\n",
    "    model.add(Input((32,32,3)))\n",
    "    #conv block 1\n",
    "    model.add(Conv2D(filters= 32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform',padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform' , padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    #conv block 2\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(keras.layers.Dropout(.2))\n",
    "    #conv block 3\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu',kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    #dense layers \n",
    "    model.add(Dense(units=256, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(Dense(units=128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(Dense(units=64, activation='relu', kernel_initializer= 'he_uniform'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(.5))\n",
    "    model.add(Dense(units=10, activation='softmax')) \n",
    "    opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/65\n",
      "50000/50000 [==============================] - 22s 436us/sample - loss: 1.9705 - accuracy: 0.3151 - val_loss: 1.3437 - val_accuracy: 0.5134\n",
      "Epoch 2/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 1.3718 - accuracy: 0.5042 - val_loss: 1.0662 - val_accuracy: 0.6175\n",
      "Epoch 3/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 1.1487 - accuracy: 0.6015 - val_loss: 0.9085 - val_accuracy: 0.6803\n",
      "Epoch 4/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 0.9946 - accuracy: 0.6639 - val_loss: 0.8286 - val_accuracy: 0.7122\n",
      "Epoch 5/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.8915 - accuracy: 0.7030 - val_loss: 0.8110 - val_accuracy: 0.7265\n",
      "Epoch 6/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.8119 - accuracy: 0.7335 - val_loss: 0.6745 - val_accuracy: 0.7684\n",
      "Epoch 7/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.7372 - accuracy: 0.7621 - val_loss: 0.6694 - val_accuracy: 0.7820\n",
      "Epoch 8/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.6764 - accuracy: 0.7828 - val_loss: 0.7293 - val_accuracy: 0.7639\n",
      "Epoch 9/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.6290 - accuracy: 0.7988 - val_loss: 0.6527 - val_accuracy: 0.7854\n",
      "Epoch 10/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.5804 - accuracy: 0.8152 - val_loss: 0.5752 - val_accuracy: 0.8119\n",
      "Epoch 11/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.5348 - accuracy: 0.8305 - val_loss: 0.6212 - val_accuracy: 0.8029\n",
      "Epoch 12/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.5073 - accuracy: 0.8403 - val_loss: 0.5888 - val_accuracy: 0.8102\n",
      "Epoch 13/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.4691 - accuracy: 0.8525 - val_loss: 0.5578 - val_accuracy: 0.8231\n",
      "Epoch 14/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.4435 - accuracy: 0.8597 - val_loss: 0.5602 - val_accuracy: 0.8251\n",
      "Epoch 15/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.4223 - accuracy: 0.8679 - val_loss: 0.5873 - val_accuracy: 0.8233\n",
      "Epoch 16/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.3960 - accuracy: 0.8743 - val_loss: 0.5878 - val_accuracy: 0.8188\n",
      "Epoch 17/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.3694 - accuracy: 0.8843 - val_loss: 0.5724 - val_accuracy: 0.8314\n",
      "Epoch 18/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.3494 - accuracy: 0.8914 - val_loss: 0.5758 - val_accuracy: 0.8321\n",
      "Epoch 19/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.3359 - accuracy: 0.8951 - val_loss: 0.5805 - val_accuracy: 0.8297\n",
      "Epoch 20/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.3165 - accuracy: 0.9024 - val_loss: 0.5970 - val_accuracy: 0.8321\n",
      "Epoch 21/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.3057 - accuracy: 0.9048 - val_loss: 0.5615 - val_accuracy: 0.8379\n",
      "Epoch 22/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.2898 - accuracy: 0.9088 - val_loss: 0.6094 - val_accuracy: 0.8286\n",
      "Epoch 23/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 0.2791 - accuracy: 0.9125 - val_loss: 0.6050 - val_accuracy: 0.8300\n",
      "Epoch 24/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.2614 - accuracy: 0.9182 - val_loss: 0.5851 - val_accuracy: 0.8389\n",
      "Epoch 25/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.2487 - accuracy: 0.9209 - val_loss: 0.6248 - val_accuracy: 0.8311\n",
      "Epoch 26/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 0.2449 - accuracy: 0.9222 - val_loss: 0.6099 - val_accuracy: 0.8327\n",
      "Epoch 27/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 0.2364 - accuracy: 0.9261 - val_loss: 0.6378 - val_accuracy: 0.8308\n",
      "Epoch 28/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.2244 - accuracy: 0.9295 - val_loss: 0.6090 - val_accuracy: 0.8385\n",
      "Epoch 29/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 0.2216 - accuracy: 0.9313 - val_loss: 0.6286 - val_accuracy: 0.8401\n",
      "Epoch 30/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 0.2099 - accuracy: 0.9338 - val_loss: 0.6568 - val_accuracy: 0.8256\n",
      "Epoch 31/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 0.2046 - accuracy: 0.9342 - val_loss: 0.6220 - val_accuracy: 0.8364\n",
      "Epoch 32/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1935 - accuracy: 0.9397 - val_loss: 0.6682 - val_accuracy: 0.8319\n",
      "Epoch 33/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1982 - accuracy: 0.9382 - val_loss: 0.7138 - val_accuracy: 0.8235\n",
      "Epoch 34/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1824 - accuracy: 0.9427 - val_loss: 0.6858 - val_accuracy: 0.8293\n",
      "Epoch 35/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1729 - accuracy: 0.9448 - val_loss: 0.6590 - val_accuracy: 0.8380\n",
      "Epoch 36/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1732 - accuracy: 0.9454 - val_loss: 0.7154 - val_accuracy: 0.8235\n",
      "Epoch 37/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1706 - accuracy: 0.9478 - val_loss: 0.6999 - val_accuracy: 0.8284\n",
      "Epoch 38/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1626 - accuracy: 0.9481 - val_loss: 0.6820 - val_accuracy: 0.8390\n",
      "Epoch 39/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1566 - accuracy: 0.9512 - val_loss: 0.6482 - val_accuracy: 0.8403\n",
      "Epoch 40/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1547 - accuracy: 0.9514 - val_loss: 0.7094 - val_accuracy: 0.8280\n",
      "Epoch 41/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1503 - accuracy: 0.9527 - val_loss: 0.6544 - val_accuracy: 0.8385\n",
      "Epoch 42/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1454 - accuracy: 0.9543 - val_loss: 0.6894 - val_accuracy: 0.8384\n",
      "Epoch 43/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 0.1475 - accuracy: 0.9545 - val_loss: 0.7211 - val_accuracy: 0.8275\n",
      "Epoch 44/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1370 - accuracy: 0.9565 - val_loss: 0.7030 - val_accuracy: 0.8386\n",
      "Epoch 45/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1383 - accuracy: 0.9569 - val_loss: 0.7086 - val_accuracy: 0.8351\n",
      "Epoch 46/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1370 - accuracy: 0.9572 - val_loss: 0.7337 - val_accuracy: 0.8314\n",
      "Epoch 47/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1323 - accuracy: 0.9591 - val_loss: 0.6906 - val_accuracy: 0.8386\n",
      "Epoch 48/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 0.1280 - accuracy: 0.9603 - val_loss: 0.6912 - val_accuracy: 0.8357\n",
      "Epoch 49/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1255 - accuracy: 0.9615 - val_loss: 0.7427 - val_accuracy: 0.8328\n",
      "Epoch 50/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1227 - accuracy: 0.9623 - val_loss: 0.7250 - val_accuracy: 0.8366\n",
      "Epoch 51/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1244 - accuracy: 0.9611 - val_loss: 0.7460 - val_accuracy: 0.8326\n",
      "Epoch 52/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1213 - accuracy: 0.9625 - val_loss: 0.7193 - val_accuracy: 0.8364\n",
      "Epoch 53/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1182 - accuracy: 0.9636 - val_loss: 0.7241 - val_accuracy: 0.8415\n",
      "Epoch 54/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1144 - accuracy: 0.9655 - val_loss: 0.7405 - val_accuracy: 0.8330\n",
      "Epoch 55/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1128 - accuracy: 0.9649 - val_loss: 0.7562 - val_accuracy: 0.8317\n",
      "Epoch 56/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1100 - accuracy: 0.9663 - val_loss: 0.7012 - val_accuracy: 0.8424\n",
      "Epoch 57/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 0.1089 - accuracy: 0.9664 - val_loss: 0.7248 - val_accuracy: 0.8370\n",
      "Epoch 58/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1099 - accuracy: 0.9661 - val_loss: 0.7156 - val_accuracy: 0.8395\n",
      "Epoch 59/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1007 - accuracy: 0.9690 - val_loss: 0.7305 - val_accuracy: 0.8433\n",
      "Epoch 60/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1077 - accuracy: 0.9670 - val_loss: 0.7015 - val_accuracy: 0.8411\n",
      "Epoch 61/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1036 - accuracy: 0.9677 - val_loss: 0.7474 - val_accuracy: 0.8359\n",
      "Epoch 62/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1080 - accuracy: 0.9666 - val_loss: 0.6907 - val_accuracy: 0.8460\n",
      "Epoch 63/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.0976 - accuracy: 0.9703 - val_loss: 0.7793 - val_accuracy: 0.8309\n",
      "Epoch 64/65\n",
      "50000/50000 [==============================] - 19s 381us/sample - loss: 0.0961 - accuracy: 0.9711 - val_loss: 0.8020 - val_accuracy: 0.8305\n",
      "Epoch 65/65\n",
      "50000/50000 [==============================] - 19s 382us/sample - loss: 0.1030 - accuracy: 0.9695 - val_loss: 0.7488 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "hist9=CNN_more_dense().fit(trainXnorm, trainYmat, epochs=65, batch_size=64, validation_data=(testXnorm, testYmat), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overall, this was worse, I think I have a good idea of how to go about this now though "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
