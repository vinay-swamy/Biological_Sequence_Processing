{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "- I have no idea what I'm doing, but lets see how this goes\n",
    "- I'm not going to bother quite yet with too much normalization\n",
    "- Ok now gonna give on loading everything manually, just gonna use the pre loaded data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, Input, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "#one hot encode Y sets\n",
    "testYmat=to_categorical(testY)\n",
    "trainYmat=to_categorical(trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize data to maximum\n",
    "trainXnorm=trainX.astype('float32') / 255.0\n",
    "testXnorm=testX.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input((32,32,3)))\n",
    "model.add(Conv2D(filters= 32, kernel_size=(3, 3), activation='relu', padding='same',))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax')) \n",
    "opt = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 550,570\n",
      "Trainable params: 550,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 18s 356us/sample - loss: 2.1435 - accuracy: 0.2143 - val_loss: 1.9221 - val_accuracy: 0.3000\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.8025 - accuracy: 0.3558 - val_loss: 1.6981 - val_accuracy: 0.3924\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.5524 - accuracy: 0.4430 - val_loss: 1.4507 - val_accuracy: 0.4774\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.4183 - accuracy: 0.4921 - val_loss: 1.3588 - val_accuracy: 0.5139\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.3105 - accuracy: 0.5336 - val_loss: 1.2588 - val_accuracy: 0.5494\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.2292 - accuracy: 0.5632 - val_loss: 1.2593 - val_accuracy: 0.5545\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.1473 - accuracy: 0.5944 - val_loss: 1.1821 - val_accuracy: 0.5807\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.0737 - accuracy: 0.6207 - val_loss: 1.1057 - val_accuracy: 0.6141\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 1.0111 - accuracy: 0.6445 - val_loss: 1.0605 - val_accuracy: 0.6268\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.9512 - accuracy: 0.6659 - val_loss: 1.0447 - val_accuracy: 0.6295\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.8911 - accuracy: 0.6893 - val_loss: 0.9932 - val_accuracy: 0.6583\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.8450 - accuracy: 0.7069 - val_loss: 0.9966 - val_accuracy: 0.6545\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.7904 - accuracy: 0.7235 - val_loss: 0.9860 - val_accuracy: 0.6552\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 13s 265us/sample - loss: 0.7390 - accuracy: 0.7426 - val_loss: 0.9322 - val_accuracy: 0.6819\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.6894 - accuracy: 0.7595 - val_loss: 0.9147 - val_accuracy: 0.6919\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.6463 - accuracy: 0.7747 - val_loss: 0.9416 - val_accuracy: 0.6874\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.5989 - accuracy: 0.7928 - val_loss: 0.9412 - val_accuracy: 0.6916\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.5511 - accuracy: 0.8071 - val_loss: 0.9676 - val_accuracy: 0.6907\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.5011 - accuracy: 0.8258 - val_loss: 0.9494 - val_accuracy: 0.7008\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.4698 - accuracy: 0.8348 - val_loss: 0.9916 - val_accuracy: 0.6901\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.4149 - accuracy: 0.8541 - val_loss: 1.0277 - val_accuracy: 0.6953\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.3846 - accuracy: 0.8641 - val_loss: 1.0538 - val_accuracy: 0.6889\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.3352 - accuracy: 0.8829 - val_loss: 1.1721 - val_accuracy: 0.6834\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 13s 266us/sample - loss: 0.3021 - accuracy: 0.8948 - val_loss: 1.1391 - val_accuracy: 0.6943\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.2689 - accuracy: 0.9049 - val_loss: 1.2176 - val_accuracy: 0.6834\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.2318 - accuracy: 0.9173 - val_loss: 1.2811 - val_accuracy: 0.6853\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.2073 - accuracy: 0.9261 - val_loss: 1.3228 - val_accuracy: 0.6913\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.1817 - accuracy: 0.9348 - val_loss: 1.4225 - val_accuracy: 0.6885\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.1574 - accuracy: 0.9440 - val_loss: 1.5284 - val_accuracy: 0.6750\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.1446 - accuracy: 0.9486 - val_loss: 1.5489 - val_accuracy: 0.6813\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.1294 - accuracy: 0.9536 - val_loss: 1.6529 - val_accuracy: 0.6803\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.1121 - accuracy: 0.9599 - val_loss: 1.6587 - val_accuracy: 0.6899\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.0952 - accuracy: 0.9669 - val_loss: 1.7820 - val_accuracy: 0.6809\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.0999 - accuracy: 0.9650 - val_loss: 1.7949 - val_accuracy: 0.6918\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0757 - accuracy: 0.9733 - val_loss: 1.9023 - val_accuracy: 0.6896\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.0680 - accuracy: 0.9766 - val_loss: 2.0557 - val_accuracy: 0.6878\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0743 - accuracy: 0.9736 - val_loss: 1.9920 - val_accuracy: 0.6976\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.0735 - accuracy: 0.9742 - val_loss: 1.9272 - val_accuracy: 0.6990\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0577 - accuracy: 0.9800 - val_loss: 2.0521 - val_accuracy: 0.6928\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0508 - accuracy: 0.9824 - val_loss: 2.2248 - val_accuracy: 0.6932\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0521 - accuracy: 0.9815 - val_loss: 2.1629 - val_accuracy: 0.6850\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.0480 - accuracy: 0.9830 - val_loss: 2.1647 - val_accuracy: 0.6943\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.0418 - accuracy: 0.9850 - val_loss: 2.1846 - val_accuracy: 0.6911\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.0419 - accuracy: 0.9860 - val_loss: 2.2779 - val_accuracy: 0.6882\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0238 - accuracy: 0.9925 - val_loss: 2.4543 - val_accuracy: 0.7009\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.0358 - accuracy: 0.9881 - val_loss: 2.5178 - val_accuracy: 0.6786\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0442 - accuracy: 0.9852 - val_loss: 2.3789 - val_accuracy: 0.6970\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0462 - accuracy: 0.9844 - val_loss: 2.3719 - val_accuracy: 0.6919\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.0294 - accuracy: 0.9904 - val_loss: 2.5066 - val_accuracy: 0.6980\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0232 - accuracy: 0.9926 - val_loss: 2.4634 - val_accuracy: 0.6990\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0262 - accuracy: 0.9913 - val_loss: 2.4522 - val_accuracy: 0.6941\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0233 - accuracy: 0.9923 - val_loss: 2.4743 - val_accuracy: 0.6998\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 0.0245 - accuracy: 0.9918 - val_loss: 2.5692 - val_accuracy: 0.7012\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0130 - accuracy: 0.9958 - val_loss: 2.5102 - val_accuracy: 0.7013\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0147 - accuracy: 0.9950 - val_loss: 2.6731 - val_accuracy: 0.7026\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0121 - accuracy: 0.9966 - val_loss: 2.6300 - val_accuracy: 0.7069\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 0.0016 - accuracy: 0.9997 - val_loss: 2.7742 - val_accuracy: 0.7079\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 7.3945e-04 - accuracy: 0.9999 - val_loss: 2.7898 - val_accuracy: 0.7139\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 1.7368e-04 - accuracy: 1.0000 - val_loss: 2.8288 - val_accuracy: 0.7121\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 1.3035e-04 - accuracy: 1.0000 - val_loss: 2.8574 - val_accuracy: 0.7129\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 1.1114e-04 - accuracy: 1.0000 - val_loss: 2.8844 - val_accuracy: 0.7129\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 9.8146e-05 - accuracy: 1.0000 - val_loss: 2.9080 - val_accuracy: 0.7128\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 8.8443e-05 - accuracy: 1.0000 - val_loss: 2.9285 - val_accuracy: 0.7129\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 8.0905e-05 - accuracy: 1.0000 - val_loss: 2.9478 - val_accuracy: 0.7135\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 7.4617e-05 - accuracy: 1.0000 - val_loss: 2.9647 - val_accuracy: 0.7140\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 6.9322e-05 - accuracy: 1.0000 - val_loss: 2.9819 - val_accuracy: 0.7144\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 6.5088e-05 - accuracy: 1.0000 - val_loss: 2.9958 - val_accuracy: 0.7149\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 6.1153e-05 - accuracy: 1.0000 - val_loss: 3.0111 - val_accuracy: 0.7148\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 5.7870e-05 - accuracy: 1.0000 - val_loss: 3.0236 - val_accuracy: 0.7149\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 5.4867e-05 - accuracy: 1.0000 - val_loss: 3.0364 - val_accuracy: 0.7155\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 5.2233e-05 - accuracy: 1.0000 - val_loss: 3.0490 - val_accuracy: 0.7153\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 4.9868e-05 - accuracy: 1.0000 - val_loss: 3.0596 - val_accuracy: 0.7151\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 4.7639e-05 - accuracy: 1.0000 - val_loss: 3.0695 - val_accuracy: 0.7153\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 4.5720e-05 - accuracy: 1.0000 - val_loss: 3.0801 - val_accuracy: 0.7148\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 4.3907e-05 - accuracy: 1.0000 - val_loss: 3.0908 - val_accuracy: 0.7145\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 4.2288e-05 - accuracy: 1.0000 - val_loss: 3.0996 - val_accuracy: 0.7145\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 4.0749e-05 - accuracy: 1.0000 - val_loss: 3.1087 - val_accuracy: 0.7146\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 13s 264us/sample - loss: 3.9357e-05 - accuracy: 1.0000 - val_loss: 3.1179 - val_accuracy: 0.7145\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 3.8043e-05 - accuracy: 1.0000 - val_loss: 3.1266 - val_accuracy: 0.7145\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 3.6812e-05 - accuracy: 1.0000 - val_loss: 3.1345 - val_accuracy: 0.7147\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 3.5691e-05 - accuracy: 1.0000 - val_loss: 3.1425 - val_accuracy: 0.7146\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 3.4631e-05 - accuracy: 1.0000 - val_loss: 3.1506 - val_accuracy: 0.7147\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 3.3648e-05 - accuracy: 1.0000 - val_loss: 3.1580 - val_accuracy: 0.7148\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 3.2704e-05 - accuracy: 1.0000 - val_loss: 3.1650 - val_accuracy: 0.7146\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 3.1828e-05 - accuracy: 1.0000 - val_loss: 3.1718 - val_accuracy: 0.7149\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 13s 263us/sample - loss: 3.0980e-05 - accuracy: 1.0000 - val_loss: 3.1789 - val_accuracy: 0.7145\n",
      "Epoch 87/100\n",
      "12352/50000 [======>.......................] - ETA: 9s - loss: 3.2744e-05 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainXnorm, trainYmat, epochs=100, batch_size=64, validation_data=(testXnorm, testYmat), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
